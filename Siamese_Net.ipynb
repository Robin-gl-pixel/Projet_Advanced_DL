{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "from numpy.random import choice as npc\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import torchvision.datasets as dset\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision.transforms as transforms\n",
    "import sys\n",
    "from collections import deque\n",
    "from torch.autograd import Variable\n",
    "from PIL import ImageFile\n",
    "from sklearn.utils import shuffle\n",
    "import itertools\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": 
    "class AnimalsTrain(Dataset):\n",
    "\n",
    "    def __init__(self, dataPath, transform=None):\n",
    "        super(AnimalsTrain, self).__init__()\n",
    "        np.random.seed(0)\n",
    "        # self.dataset = dataset\n",
    "        self.transform = transform\n",
    "        self.datas, self.num_classes = self.loadToMem(dataPath)\n",
    "        #print(self.num_classes,len(self.datas[0]))\n",
    "        idx = 0\n",
    "        for dossier in os.listdir(dataPath):\n",
    "            datas[idx] = []\n",
    "            for filename in os.listdir(os.path.join(dataPath, dossier)):\n",
    "                filePath = os.path.join(dataPath, dossier, filename)\n",
    "                datas[idx].append(np.array(Image.open(filePath).convert('RGB')))\n",
    "            idx += 1\n",
=======
    "        agrees = [0, 90, 180, 270]\n",
    "        idx = 0\n",
    "        for agree in agrees:\n",
    "            for alphaPath in os.listdir(dataPath):\n",
    "                for charPath in os.listdir(os.path.join(dataPath, alphaPath)):\n",
    "                    datas[idx] = []\n",
    "                    for samplePath in os.listdir(os.path.join(dataPath, alphaPath, charPath)):\n",
    "                        filePath = os.path.join(dataPath, alphaPath, charPath, samplePath)\n",
    "                        datas[idx].append(Image.open(filePath).rotate(agree).convert('L'))\n",
    "                    idx += 1\n",


    "            image1 = Image.fromarray(random.choice(self.datas[idx1]),'RGB')\n",
    "            image2 = Image.fromarray(random.choice(self.datas[idx1]),'RGB')\n",
=======
    "            image1 = random.choice(self.datas[idx1])\n",
    "            image2 = random.choice(self.datas[idx1])\n",

    "            image1 = Image.fromarray(random.choice(self.datas[idx1]),'RGB')\n",
    "            image2 = Image.fromarray(random.choice(self.datas[idx2]),'RGB')\n",
=======
    "            image1 = random.choice(self.datas[idx1])\n",
    "            image2 = random.choice(self.datas[idx2])\n",


    "class AnimalsTest(Dataset):\n",
    "\n",
    "    def __init__(self, dataPath, transform=None, times=200, way=20):\n",
    "        np.random.seed(1)\n",
    "        super(AnimalsTest, self).__init__()\n",
=======
    "class OmniglotTest(Dataset):\n",
    "\n",
    "    def __init__(self, dataPath, transform=None, times=200, way=20):\n",
    "        np.random.seed(1)\n",
    "        super(OmniglotTest, self).__init__()\n",


    "        print(\"begin loading testing dataset to memory\")\n",
    "        datas = {}\n",
    "        idx = 0\n",
    "        for dossier in os.listdir(dataPath):\n",
    "            datas[idx] = []\n",
    "            for filename in os.listdir(os.path.join(dataPath, dossier)):\n",
    "                filePath = os.path.join(dataPath, dossier, filename)\n",
    "                datas[idx].append(np.array(Image.open(filePath)))\n",
    "            idx += 1\n",
    "        print(\"finish loading testing dataset to memory\")\n",
    "        return datas, idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return 2000\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # image1 = random.choice(self.dataset.imgs)\n",
    "        label = None\n",
    "        img1 = None\n",
    "        img2 = None\n",
    "        # get image from same class\n",
    "        if index % 2 == 1:\n",
    "            label = 1.0\n",
    "            idx1 = random.randint(0, self.num_classes - 1)\n",
    "            image1 = Image.fromarray(random.choice(self.datas[idx1]),'RGB')\n",
    "            image2 = Image.fromarray(random.choice(self.datas[idx1]),'RGB')\n",
    "        # get image from different class\n",
    "        else:\n",
    "            label = 0.0\n",
    "            idx1 = random.randint(0, self.num_classes - 1)\n",
    "            idx2 = random.randint(0, self.num_classes - 1)\n",
    "            while idx1 == idx2:\n",
    "                idx2 = random.randint(0, self.num_classes - 1)\n",
    "            image1 = Image.fromarray(random.choice(self.datas[idx1]),'RGB')\n",
    "            image2 = Image.fromarray(random.choice(self.datas[idx2]),'RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image1 = self.transform(image1)\n",
    "            image2 = self.transform(image2)\n",
    "        return image1, image2, torch.from_numpy(np.array([label], dtype=np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On définit le réseau que nous allons utiliser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Siamese(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Siamese, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 10),  # 64@96*96\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),  # 64@48*48\n",
    "            #nn.Dropout(0.25),\n",
    "            nn.Conv2d(64, 128, 7),\n",
    "            nn.ReLU(),    # 128@42*42\n",
    "            nn.MaxPool2d(2),   # 128@21*21\n",
    "            #nn.Dropout(0.25),\n",
    "            nn.Conv2d(128, 128, 4),\n",
    "            nn.ReLU(), # 128@18*18\n",
    "            nn.MaxPool2d(2), # 128@9*9\n",
    "            #nn.Dropout(0.25),\n",
    "            nn.Conv2d(128, 256, 4),\n",
    "            nn.ReLU(),   # 256@6*6\n",
    "        )\n",
    "        self.liner = nn.Sequential(nn.Linear(9216, 4096), nn.ReLU(inplace=True))\n",
    "        self.out = nn.Linear(4096, 1)\n",
    "    \n",
    "    def extract(self,x1,x2):\n",
    "        out1 = self.forward_one(x1)\n",
    "        out2 = self.forward_one(x2)\n",
    "        dis = torch.abs(out1 - out2)\n",
    "        return (dis)\n",
    "\n",
    "    def forward_one(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self.liner(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        out1 = self.forward_one(x1)\n",
    "        out2 = self.forward_one(x2)\n",
    "        dis = torch.abs(out1 - out2)\n",
    "        #dis = self.inter(dis)\n",
    "        out = self.out(dis)\n",
    "        return torch.sigmoid(out)\n",
    "        #return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'data/train/'\n",
    "test_path = 'data/test/'\n",
    "train_os_path = 'data/train_os/'\n",
    "test_os_path = 'data/test_os/'\n",
    "model_path = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "        transforms.Resize((105,105)),\n",
    "        transforms.RandomHorizontalFlip(0.5),\n",
    "        #transforms.RandomAffine(15),\n",
    "        transforms.ToTensor()])\n",
    "test_transforms = transforms.Compose([\n",
    "        transforms.Resize((105,105)),\n",
    "        #transforms.RandomAffine(15),\n",
    "        transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin loading training dataset to memory\n",
      "finish loading training dataset to memory\n",
      "begin loading testing dataset to memory\n",
      "finish loading testing dataset to memory\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Siamese(\n",
       "  (conv): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(10, 10), stride=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 128, kernel_size=(7, 7), stride=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(128, 128, kernel_size=(4, 4), stride=(1, 1))\n",
       "    (7): ReLU()\n",
       "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (9): Conv2d(128, 256, kernel_size=(4, 4), stride=(1, 1))\n",
       "    (10): ReLU()\n",
       "  )\n",
       "  (liner): Sequential(\n",
       "    (0): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (out): Linear(in_features=4096, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainSet = AnimalsTrain(train_path, transform=train_transforms)\n",
    "testSet = AnimalsTest(test_path, transform=test_transforms)\n",
    "testLoader = DataLoader(testSet, batch_size=20, shuffle=True, num_workers=4)\n",
    "\n",
    "trainLoader = DataLoader(trainSet, batch_size=32, shuffle=True, num_workers=4)\n",
    "\n",
    "#loss_fn = torch.nn.BCEWithLogitsLoss(reduction='mean')\n",
    "loss_fn = torch.nn.BCELoss(reduction='mean')\n",
    "net = Siamese()\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr = 0.00006)\n",
    "optimizer.zero_grad()\n",
    "\n",
    "net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tloss:\t0.68437\ttime lapsed:\t257.31 s\n",
      "[200]\tloss:\t0.66280\ttime lapsed:\t255.22 s\n",
      "[300]\tloss:\t0.64997\ttime lapsed:\t255.22 s\n",
      "[400]\tloss:\t0.64018\ttime lapsed:\t254.74 s\n",
      "[500]\tloss:\t0.62700\ttime lapsed:\t254.02 s\n",
      "**********************************************************************\n",
      "[500]\tTest set\tcorrect:\t1240\terror:\t760\tprecision:\t0.620000\n",
      "**********************************************************************\n",
      "[600]\tloss:\t0.61195\ttime lapsed:\t312.34 s\n",
      "[700]\tloss:\t0.60365\ttime lapsed:\t263.98 s\n",
      "[800]\tloss:\t0.58408\ttime lapsed:\t268.55 s\n",
      "[900]\tloss:\t0.56368\ttime lapsed:\t266.16 s\n",
      "[1000]\tloss:\t0.56373\ttime lapsed:\t266.44 s\n",
      "**********************************************************************\n",
      "[1000]\tTest set\tcorrect:\t1370\terror:\t630\tprecision:\t0.685000\n",
      "**********************************************************************\n",
      "[1100]\tloss:\t0.56465\ttime lapsed:\t320.78 s\n",
      "[1200]\tloss:\t0.53572\ttime lapsed:\t266.83 s\n",
      "[1300]\tloss:\t0.54411\ttime lapsed:\t266.57 s\n",
      "[1400]\tloss:\t0.52828\ttime lapsed:\t265.56 s\n",
      "[1500]\tloss:\t0.51289\ttime lapsed:\t265.94 s\n",
      "**********************************************************************\n",
      "[1500]\tTest set\tcorrect:\t1428\terror:\t572\tprecision:\t0.714000\n",
      "**********************************************************************\n",
      "[1600]\tloss:\t0.50092\ttime lapsed:\t317.45 s\n",
      "[1700]\tloss:\t0.50562\ttime lapsed:\t263.90 s\n",
      "[1800]\tloss:\t0.46781\ttime lapsed:\t265.29 s\n",
      "[1900]\tloss:\t0.47482\ttime lapsed:\t264.53 s\n",
      "[2000]\tloss:\t0.43712\ttime lapsed:\t265.46 s\n",
      "**********************************************************************\n",
      "[2000]\tTest set\tcorrect:\t1517\terror:\t483\tprecision:\t0.758500\n",
      "**********************************************************************\n",
      "[2100]\tloss:\t0.44026\ttime lapsed:\t317.46 s\n",
      "[2200]\tloss:\t0.43623\ttime lapsed:\t264.40 s\n",
      "[2300]\tloss:\t0.40834\ttime lapsed:\t266.09 s\n",
      "[2400]\tloss:\t0.37610\ttime lapsed:\t265.73 s\n",
      "[2500]\tloss:\t0.36634\ttime lapsed:\t266.12 s\n",
      "**********************************************************************\n",
      "[2500]\tTest set\tcorrect:\t1564\terror:\t436\tprecision:\t0.782000\n",
      "**********************************************************************\n",
      "[2600]\tloss:\t0.37069\ttime lapsed:\t318.76 s\n",
      "[2700]\tloss:\t0.34819\ttime lapsed:\t267.58 s\n",
      "[2800]\tloss:\t0.33291\ttime lapsed:\t267.21 s\n",
      "[2900]\tloss:\t0.31673\ttime lapsed:\t266.24 s\n",
      "[3000]\tloss:\t0.30379\ttime lapsed:\t266.49 s\n",
      "**********************************************************************\n",
      "[3000]\tTest set\tcorrect:\t1596\terror:\t404\tprecision:\t0.798000\n",
      "**********************************************************************\n",
      "[3100]\tloss:\t0.28499\ttime lapsed:\t319.51 s\n",
      "[3200]\tloss:\t0.27430\ttime lapsed:\t266.87 s\n",
      "[3300]\tloss:\t0.26990\ttime lapsed:\t267.38 s\n",
      "[3400]\tloss:\t0.25805\ttime lapsed:\t267.59 s\n",
      "[3500]\tloss:\t0.23910\ttime lapsed:\t265.78 s\n",
      "**********************************************************************\n",
      "[3500]\tTest set\tcorrect:\t1610\terror:\t390\tprecision:\t0.805000\n",
      "**********************************************************************\n",
      "[3600]\tloss:\t0.22405\ttime lapsed:\t319.88 s\n",
      "[3700]\tloss:\t0.22748\ttime lapsed:\t268.13 s\n",
      "[3800]\tloss:\t0.21654\ttime lapsed:\t267.94 s\n",
      "[3900]\tloss:\t0.20075\ttime lapsed:\t266.85 s\n",
      "[4000]\tloss:\t0.19386\ttime lapsed:\t266.55 s\n",
      "**********************************************************************\n",
      "[4000]\tTest set\tcorrect:\t1656\terror:\t344\tprecision:\t0.828000\n",
      "**********************************************************************\n",
      "[4100]\tloss:\t0.18556\ttime lapsed:\t320.16 s\n",
      "[4200]\tloss:\t0.17739\ttime lapsed:\t265.68 s\n",
      "[4300]\tloss:\t0.17446\ttime lapsed:\t266.17 s\n",
      "[4400]\tloss:\t0.17840\ttime lapsed:\t266.30 s\n",
      "[4500]\tloss:\t0.15751\ttime lapsed:\t267.29 s\n",
      "**********************************************************************\n",
      "[4500]\tTest set\tcorrect:\t1670\terror:\t330\tprecision:\t0.835000\n",
      "**********************************************************************\n",
      "[4600]\tloss:\t0.14864\ttime lapsed:\t319.34 s\n",
      "[4700]\tloss:\t0.15874\ttime lapsed:\t267.35 s\n",
      "[4800]\tloss:\t0.14329\ttime lapsed:\t267.60 s\n",
      "[4900]\tloss:\t0.15151\ttime lapsed:\t267.50 s\n",
      "[5000]\tloss:\t0.13960\ttime lapsed:\t267.07 s\n",
      "**********************************************************************\n",
      "[5000]\tTest set\tcorrect:\t1676\terror:\t324\tprecision:\t0.838000\n",
      "**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "loss_val = 0\n",
    "time_start = time.time()\n",
    "max_iter = 5000\n",
    "show_every = 100\n",
    "save_every = 1000\n",
    "test_every = 500\n",
    "\n",
    "for batch_id, (img1, img2, label) in enumerate(trainLoader, 1):\n",
    "    #print(img1.shape)\n",
    "    if batch_id > max_iter:\n",
    "        break\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        img1, img2, label = Variable(img1.cuda()), Variable(img2.cuda()), Variable(label.cuda())\n",
    "    else:\n",
    "        img1, img2, label = Variable(img1), Variable(img2), Variable(label)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    output = net.forward(img1, img2)\n",
    "    #print(output)\n",
    "    loss = loss_fn(output, label)\n",
    "    loss_val += loss.item()\n",
    "    #print(loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if batch_id % show_every == 0 :\n",
    "        print('[%d]\\tloss:\\t%.5f\\ttime lapsed:\\t%.2f s'%(batch_id, loss_val/show_every, time.time() - time_start))\n",
    "        loss_val = 0\n",
    "        time_start = time.time()\n",
    "    if batch_id % save_every == 0:\n",
    "        torch.save(net.state_dict(), model_path + 'model-inter-' + str(batch_id+1) + \".pt\")\n",
    "    if batch_id % test_every == 0:\n",
    "        right, error = 0, 0\n",
    "        for _, (img1, img2, label) in enumerate(testLoader, 1):\n",
    "            if torch.cuda.is_available():\n",
    "                img1, img2, label = Variable(img1.cuda()), Variable(img2.cuda()), Variable(label.cuda())\n",
    "            else:\n",
    "                img1, img2, label = Variable(img1), Variable(img2), Variable(label)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output = net(img1, img2)\n",
    "            #pred = np.argmax(output)\n",
    "            #print(output,label)\n",
    "            output = torch.div(output*2,1, rounding_mode='trunc')\n",
    "            right += sum(output==label)\n",
    "            error += len(label)-sum(output==label)\n",
    "        print('*'*70)\n",
    "        print('[%d]\\tTest set\\tcorrect:\\t%d\\terror:\\t%d\\tprecision:\\t%f'%(batch_id, right, error, right*1.0/(right+error)))\n",
    "        print('*'*70)\n",
    "    train_loss.append(loss_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On regarde dans un premier temps le score obtenu par le réseau avant qu'il ne voie les images du One Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(torch.load('model-inter-5001.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Siamese(\n",
       "  (conv): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(10, 10), stride=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 128, kernel_size=(7, 7), stride=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(128, 128, kernel_size=(4, 4), stride=(1, 1))\n",
       "    (7): ReLU()\n",
       "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (9): Conv2d(128, 256, kernel_size=(4, 4), stride=(1, 1))\n",
       "    (10): ReLU()\n",
       "  )\n",
       "  (liner): Sequential(\n",
       "    (0): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (out): Linear(in_features=4096, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnimalsPredict(Dataset):\n",
    "\n",
    "    def __init__(self, dataPath_train, dataPath_test, transform=None):\n",
    "        np.random.seed(1)\n",
    "        super(AnimalsPredict, self).__init__()\n",
    "        self.transform = transform\n",
    "        self.datas_train, self.num_classes = self.loadToMem(dataPath_train)\n",
    "        self.datas_test, self.num_classes = self.loadToMem(dataPath_test)\n",
    "        self.dict = list(self.datas_test.keys())\n",
    "        #print(self.dict)\n",
    "        self.images = np.array(list(itertools.chain(*list(self.datas_test.values()))))\n",
    "        self.labels = np.array(list(itertools.chain(*[[i for j in range (len(self.datas_test[self.dict[i]]))] \n",
    "                                                      for i in range (self.num_classes)])))\n",
    "        self.images, self.labels = shuffle(self.images, self.labels)\n",
    "\n",
    "    def loadToMem(self, dataPath):\n",
    "        print(\"begin loading testing dataset to memory\")\n",
    "        datas = {}\n",
    "        for dossier in os.listdir(dataPath):\n",
    "            datas[dossier] = []\n",
    "            for filename in os.listdir(os.path.join(dataPath, dossier)):\n",
    "                filePath = os.path.join(dataPath, dossier, filename)\n",
    "                datas[dossier].append(np.array(Image.open(filePath)))\n",
    "        print(\"finish loading testing dataset to memory\")\n",
    "        return datas, len(datas)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_classes*len(self.images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        index  = index %(self.num_classes*len(self.images))\n",
    "        idx = index // self.num_classes\n",
    "        classe = self.dict[index % self.num_classes]\n",
    "        img1 = Image.fromarray(self.images[idx],'RGB')\n",
    "        img2 = Image.fromarray(self.datas_train[classe][0],'RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            img1 = self.transform(img1)\n",
    "            img2 = self.transform(img2)\n",
    "        return img1, img2, self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin loading testing dataset to memory\n",
      "finish loading testing dataset to memory\n",
      "begin loading testing dataset to memory\n",
      "finish loading testing dataset to memory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_45/2329885197.py:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  self.images = np.array(list(itertools.chain(*list(self.datas_test.values()))))\n"
     ]
    }
   ],
   "source": [
    "PredictSet = AnimalsPredict(train_os_path, test_os_path, transform=test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "PredictLoader = DataLoader(PredictSet, batch_size=5, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "right, error = 0, 0\n",
    "y_pred = []\n",
    "y_true = []\n",
    "for i, (test1, test2, classe) in enumerate(PredictLoader, 1):\n",
    "    if i>=497:\n",
    "        break\n",
    "    if torch.cuda.is_available():\n",
    "        test1, test2 = test1.cuda(), test2.cuda()\n",
    "    test1, test2 = Variable(test1), Variable(test2)\n",
    "    with torch.no_grad():\n",
    "        output = net.forward(test1, test2).data.cpu().numpy()\n",
    "    #print(output)\n",
    "    pred = np.argmax(output)\n",
    "    #print(output)\n",
    "    y_pred.append(pred)\n",
    "    y_true.append(classe[0])\n",
    "    #print(pred,classe)\n",
    "    if pred == classe[0]:\n",
    "        right += 1\n",
    "    else: error += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict set\tcorrect:\t168\terror:\t328\tscore:\t0.338710\n"
     ]
    }
   ],
   "source": [
    "print('Predict set\\tcorrect:\\t%d\\terror:\\t%d\\tscore:\\t%f'%( right, error, right*1.0/(right+error)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[28 10  0 49 13]\n",
      " [ 1 38  8 51  0]\n",
      " [ 5 10 10 69  5]\n",
      " [ 1 15 15 69  0]\n",
      " [12 14  3 47 23]]\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix')\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(cf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.heatmap(cf_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant, on va réentrainer le réseau sur les paires crées par les images du One Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnimalsTrain_OS(Dataset):\n",
    "\n",
    "    def __init__(self, dataPath, transform=None):\n",
    "        super(AnimalsTrain_OS, self).__init__()\n",
    "        np.random.seed(0)\n",
    "        # self.dataset = dataset\n",
    "        self.transform = transform\n",
    "        self.datas, self.num_classes = self.loadToMem(dataPath)\n",
    "        #print(self.num_classes,len(self.datas[0]))\n",
    "\n",
    "    def loadToMem(self, dataPath):\n",
    "        print(\"begin loading training dataset to memory\")\n",
    "        datas = {}\n",
    "        idx = 0\n",
    "        for dossier in os.listdir(dataPath):\n",
    "            datas[idx] = []\n",
    "            for filename in os.listdir(os.path.join(dataPath, dossier)):\n",
    "                filePath = os.path.join(dataPath, dossier, filename)\n",
    "                datas[idx].append(np.array(Image.open(filePath).convert('RGB')))\n",
    "            idx += 1\n",
    "        print(\"finish loading training dataset to memory\")\n",
    "        return datas, idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return  21000000\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # image1 = random.choice(self.dataset.imgs)\n",
    "        label = None\n",
    "        img1 = None\n",
    "        img2 = None\n",
    "        # get image from same class\n",
    "        if index % 5 == 1:\n",
    "            label = 1.0\n",
    "            idx1 = random.randint(0, self.num_classes - 1)\n",
    "            image1 = Image.fromarray(random.choice(self.datas[idx1]),'RGB')\n",
    "            image2 = Image.fromarray(random.choice(self.datas[idx1]),'RGB')\n",
    "        # get image from different class\n",
    "        else:\n",
    "            label = 0.0\n",
    "            idx1 = random.randint(0, self.num_classes - 1)\n",
    "            idx2 = random.randint(0, self.num_classes - 1)\n",
    "            while idx1 == idx2:\n",
    "                idx2 = random.randint(0, self.num_classes - 1)\n",
    "            image1 = Image.fromarray(random.choice(self.datas[idx1]),'RGB')\n",
    "            image2 = Image.fromarray(random.choice(self.datas[idx2]),'RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image1 = self.transform(image1)\n",
    "            image2 = self.transform(image2)\n",
    "        return image1, image2, torch.from_numpy(np.array([label], dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin loading training dataset to memory\n",
      "finish loading training dataset to memory\n"
     ]
    }
   ],
   "source": [
    "trainSet_os = AnimalsTrain_OS(train_os_path, transform=train_transforms)\n",
    "\n",
    "trainLoader_os = DataLoader(trainSet_os, batch_size=8, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\tloss:\t0.05826\ttime lapsed:\t13.77 s\n",
      "Predict set\tcorrect:\t177\terror:\t319\tscore:\t0.356855\n",
      "[20]\tloss:\t0.09130\ttime lapsed:\t88.99 s\n",
      "Predict set\tcorrect:\t175\terror:\t321\tscore:\t0.352823\n",
      "[30]\tloss:\t0.05804\ttime lapsed:\t87.13 s\n",
      "Predict set\tcorrect:\t176\terror:\t320\tscore:\t0.354839\n",
      "[40]\tloss:\t0.09115\ttime lapsed:\t87.82 s\n",
      "Predict set\tcorrect:\t174\terror:\t322\tscore:\t0.350806\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_45/2438308457.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m#print(loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbatch_id\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mshow_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[%d]\\tloss:\\t%.5f\\ttime lapsed:\\t%.2f s'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_val\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mshow_every\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    131\u001b[0m                     \u001b[0mstate_steps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             F.adam(params_with_grad,\n\u001b[0m\u001b[1;32m    134\u001b[0m                    \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                    \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net.train()\n",
    "train_loss = []\n",
    "loss_val = 0\n",
    "time_start = time.time()\n",
    "max_iter = 200\n",
    "show_every = 10\n",
    "save_every = 10\n",
    "test_every = 10\n",
    "\n",
    "for batch_id, (img1, img2, label) in enumerate(trainLoader_os, 1):\n",
    "    net.train()\n",
    "    #print(img1.shape)\n",
    "    if batch_id > max_iter:\n",
    "        break\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        img1, img2, label = Variable(img1.cuda()), Variable(img2.cuda()), Variable(label.cuda())\n",
    "    else:\n",
    "        img1, img2, label = Variable(img1), Variable(img2), Variable(label)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    output = net.forward(img1, img2)\n",
    "    #print(output)\n",
    "    loss = loss_fn(output, label)\n",
    "    loss_val += loss.item()\n",
    "    #print(loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if batch_id % show_every == 0 :\n",
    "        print('[%d]\\tloss:\\t%.5f\\ttime lapsed:\\t%.2f s'%(batch_id, loss_val/show_every, time.time() - time_start))\n",
    "        loss_val = 0\n",
    "        time_start = time.time()\n",
    "    if batch_id % save_every == 0:\n",
    "        torch.save(net.state_dict(), model_path + 'model-os-inter-' + str(batch_id+1) + \".pt\")\n",
    "    if batch_id % test_every == 0:\n",
    "        net.eval()\n",
    "        right, error = 0, 0\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        for i, (test1, test2, classe) in enumerate(PredictLoader, 1):\n",
    "            if i>=497:\n",
    "                break\n",
    "            if torch.cuda.is_available():\n",
    "                test1, test2 = test1.cuda(), test2.cuda()\n",
    "            test1, test2 = Variable(test1), Variable(test2)\n",
    "            with torch.no_grad():\n",
    "                output = net.forward(test1, test2).data.cpu().numpy()\n",
    "            pred = np.argmax(output)\n",
    "            #print(output)\n",
    "            y_pred.append(pred)\n",
    "            y_true.append(classe[0])\n",
    "            #print(pred,classe)\n",
    "            if pred == classe[0]:\n",
    "                right += 1\n",
    "            else: error += 1\n",
    "        print('Predict set\\tcorrect:\\t%d\\terror:\\t%d\\tscore:\\t%f'%( right, error, right*1.0/(right+error)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right, error = 0, 0\n",
    "y_pred = []\n",
    "y_true = []\n",
    "for i, (test1, test2, classe) in enumerate(PredictLoader, 1):\n",
    "    if i>=497:\n",
    "        break\n",
    "    if torch.cuda.is_available():\n",
    "        test1, test2 = test1.cuda(), test2.cuda()\n",
    "    test1, test2 = Variable(test1), Variable(test2)\n",
    "    with torch.no_grad():\n",
    "        output = net.forward(test1, test2).data.cpu().numpy()\n",
    "    #print(output)\n",
    "    pred = np.argmax(output)\n",
    "    #print(output)\n",
    "    y_pred.append(pred)\n",
    "    y_true.append(classe[0])\n",
    "    #print(pred,classe)\n",
    "    if pred == classe[0]:\n",
    "        right += 1\n",
    "    else: error += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict set\tcorrect:\t170\terror:\t326\tprecision:\t0.342742\n"
     ]
    }
   ],
   "source": [
    "print('Predict set\\tcorrect:\\t%d\\terror:\\t%d\\tprecision:\\t%f'%( right, error, right*1.0/(right+error)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Predict set\\tcorrect:\\t%d\\terror:\\t%d\\tprecision:\\t%f'%( right, error, right*1.0/(right+error)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Confusion Matrix')\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(cf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.heatmap(cf_matrix, annot=True)"
=======
    "        print(\"begin loading test dataset to memory\")\n",
    "        datas = {}\n",
    "        idx = 0\n",
    "        for alphaPath in os.listdir(dataPath):\n",
    "            for charPath in os.listdir(os.path.join(dataPath, alphaPath)):\n",
    "                datas[idx] = []\n",
    "                for samplePath in os.listdir(os.path.join(dataPath, alphaPath, charPath)):\n",
    "                    filePath = os.path.join(dataPath, alphaPath, charPath, samplePath)\n",
    "                    datas[idx].append(Image.open(filePath).convert('L'))\n",
    "                idx += 1\n",
    "        print(\"finish loading test dataset to memory\")\n",
    "        return datas, idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.times * self.way\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        idx = index % self.way\n",
    "        label = None\n",
    "        # generate image pair from same class\n",
    "        if idx == 0:\n",
    "            self.c1 = random.randint(0, self.num_classes - 1)\n",
    "            self.img1 = random.choice(self.datas[self.c1])\n",
    "            img2 = random.choice(self.datas[self.c1])\n",
    "        # generate image pair from different class\n",
    "        else:\n",
    "            c2 = random.randint(0, self.num_classes - 1)\n",
    "            while self.c1 == c2:\n",
    "                c2 = random.randint(0, self.num_classes - 1)\n",
    "            img2 = random.choice(self.datas[c2])\n",
    "\n",
    "        if self.transform:\n",
    "            img1 = self.transform(self.img1)\n",
    "            img2 = self.transform(img2)\n",
    "        return img1, img2"

   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
=======
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"


   "version": "3.9.9"
=======
   "version": "3.7.6"
    }
